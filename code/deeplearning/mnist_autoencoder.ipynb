{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "mnist_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I36wQ6WNyb39",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MNIST Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOCjEtiVyeid",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5-bGurjyUwO",
    "outputId": "779c6bab-a05f-423f-c3aa-c7592886839d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "try:\n",
    "    from cloudmesh.common.StopWatch import StopWatch\n",
    "except:  # noqa: E722\n",
    "    ! pip install cloudmesh-common\n",
    "    from cloudmesh.common.StopWatch import StopWatch\n",
    "from cloudmesh.common.Shell import Shell"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hphaPWTTykQ3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=0 pid=8968\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=0 pid=8968'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWatch.start(\"total\")\n",
    "StopWatch.start(\"import\")\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "StopWatch.stop(\"import\")\n",
    "StopWatch.progress(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save(file):\n",
    "    name = os.path.basename(file).replace(\".py\", \"\")\n",
    "    cwd = Shell.map_filename(\".\").path\n",
    "    Shell.mkdir(f\"{cwd}/images\")\n",
    "    plt.savefig(f'{cwd}/images/{name}.png',dpi=300)\n",
    "    plt.savefig(f'{cwd}/images/{name}.pdf')\n",
    "    plt.savefig(f'{cwd}/images/{name}.svg')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Process Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=20 pid=8968\n"
     ]
    }
   ],
   "source": [
    "StopWatch.start(\"data-load\")\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "StopWatch.stop(\"data-load\")\n",
    "StopWatch.progress(20)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "hidden_units = [32, 64]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28, 28, 32)        64        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28, 28, 64)        2112      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " latent_vector (Dense)       (None, 16)                802832    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,008\n",
      "Trainable params: 805,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50176)             852992    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 28, 28, 32)        2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 28, 28, 64)        2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 28, 28, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 857,249\n",
      "Trainable params: 857,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                805008    \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         857249    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,662,257\n",
      "Trainable params: 1,662,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "# cloudmesh status=running progress=40 pid=8968\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=40 pid=8968'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWatch.start(\"define-model\")\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "x = Dense(hidden_units[0], activation='relu')(x)\n",
    "x = Dense(hidden_units[1], activation='relu')(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs,\n",
    "                latent,\n",
    "                name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder,\n",
    "           to_file='images/encoder.png',\n",
    "           show_shapes=True)\n",
    "\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "x = Dense(hidden_units[0], activation='relu')(x)\n",
    "x = Dense(hidden_units[1], activation='relu')(x)\n",
    "\n",
    "outputs = Dense(1, activation='relu')(x)\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='images/decoder.png', show_shapes=True)\n",
    "\n",
    "autoencoder = Model(inputs,\n",
    "                    decoder(encoder(inputs)),\n",
    "                    name='autoencoder')\n",
    "autoencoder.summary()\n",
    "plot_model(autoencoder,\n",
    "           to_file='images/autoencoder.png',\n",
    "           show_shapes=True)\n",
    "StopWatch.start('compile')\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "StopWatch.stop('compile')\n",
    "StopWatch.stop(\"define-model\")\n",
    "StopWatch.progress(40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 404/1875 [=====>........................] - ETA: 38s - loss: 0.0284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StopWatch.start(\"train\")\n",
    "autoencoder.fit(x_train,\n",
    "                x_train,\n",
    "                validation_data=(x_test, x_test),\n",
    "                epochs=1,\n",
    "                batch_size=batch_size)\n",
    "StopWatch.stop(\"train\")\n",
    "StopWatch.progress(60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "StopWatch.start(\"test\")\n",
    "x_decoded = autoencoder.predict(x_test)\n",
    "StopWatch.stop(\"test\")\n",
    "StopWatch.progress(80)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "StopWatch.start(\"visualize\")\n",
    "imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n",
    "imgs = imgs.reshape((4, 4, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "save('input_and_decoded.png')\n",
    "StopWatch.stop(\"visualize\")\n",
    "StopWatch.stop(\"total\")\n",
    "StopWatch.progress(100)\n",
    "user = os.environ['USERNAME']\n",
    "gpuname = 'TODO'\n",
    "tag = 'mnist_autoencoder'\n",
    "StopWatch.benchmark(tag=tag, node=gpuname, user=user)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}