{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "mnist_with_pytorch.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5achl3MnYXU"
   },
   "source": [
    "# MNIST With PyTorch Training\n",
    "This program runs in about 52.337 seconds (Windows 11, i7, 16 GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncnRNj6wndZj"
   },
   "source": [
    "## Prerequisites\n",
    "Install the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "try:\n",
    "    from cloudmesh.common.StopWatch import StopWatch\n",
    "except:  # noqa: E722\n",
    "    ! pip install cloudmesh-common\n",
    "    from cloudmesh.common.StopWatch import StopWatch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nOB2NoPxlSep"
   },
   "source": [
    "StopWatch.start('total')\n",
    "StopWatch.start('import')\n",
    "\n",
    "import os    # noqa: E402\n",
    "import cpuinfo    # noqa: E402\n",
    "import torch    # noqa: E402\n",
    "from torchvision import datasets, transforms    # noqa: E402\n",
    "from torch import nn    # noqa: E402\n",
    "from torch import optim    # noqa: E402\n",
    "from keras.datasets import mnist    # noqa: E402\n",
    "from cloudmesh.common.systeminfo import os_is_windows    # noqa: E402\n",
    "from cloudmesh.common.Shell import Shell    # noqa: E402\n",
    "\n",
    "filename = Shell.map_filename(f'~/reu2022/code/deeplearning/mnist/mnist_with_pytorch.log')\n",
    "StopWatch.progress(0, filename=filename)\n",
    "\n",
    "StopWatch.stop('import')\n",
    "StopWatch.progress(6, filename=filename)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=0 pid=2156\n",
      "# cloudmesh status=running progress=2 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=2 pid=2156'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=9 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=9 pid=2156'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWatch.start(\"data-load\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "StopWatch.stop(\"data-load\")\n",
    "StopWatch.progress(7, filename=filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbt5QydhnfqH"
   },
   "source": [
    "## Pre-Process Data\n",
    "\n",
    "Here we download the data using PyTorch data utils and transform the data by using a normalization function. PyTorch provides a data loader abstraction called a `DataLoader` where we can set the batch size, data shuffle per batch loading. Each data loader expecte a Pytorch Dataset. The DataSet abstraction and DataLoader usage can be found [here](https://pytorch.org/tutorials/recipes/recipes/loading_data_recipe.html) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yWKZO4sHlhSQ"
   },
   "source": [
    "StopWatch.start(\"data-pre-process\")\n",
    "\n",
    "# Data transformation function\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# DataSet\n",
    "train_data_set = datasets.MNIST('pytorch/My Drive/mnist/data/', download=True, train=True, transform=transform)\n",
    "validation_data_set = datasets.MNIST('pytorch/My Drive/mnist/data/', download=True, train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data_set, batch_size=32, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data_set, batch_size=32, shuffle=True)\n",
    "\n",
    "StopWatch.stop(\"data-pre-process\")\n",
    "StopWatch.progress(8, filename=filename)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=3 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=3 pid=2156'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXrmy7jYniQn"
   },
   "source": [
    "## Define Model\n",
    "\n",
    "Here we select the matching input size compared to the network definition. \n",
    "Here data reshaping or layer reshaping must be done to match input data shape with the network input shape. Also we define a set of hidden unit sizes along with the output layers size. The `output_size` must match with the number of labels associated with the classification problem. The hidden units can be chosesn depending on the problem. `nn.Sequential` is one way to create the network. Here we stack a set of linear layers along with a softmax layer for the classification as the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k65r0ZeHlzgY",
    "outputId": "f78eba4c-144a-436b-888f-464c7cd95488"
   },
   "source": [
    "StopWatch.start(\"define-model\")\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 128, 64, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[3], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "print(model)\n",
    "\n",
    "StopWatch.stop(\"define-model\")\n",
    "StopWatch.progress(9, filename=filename)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (9): LogSoftmax(dim=1)\n",
      ")\n",
      "# cloudmesh status=running progress=4 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=4 pid=2156'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzRdJkNJn3iB"
   },
   "source": [
    "## Define Loss Function and Optimizer\n",
    "\n",
    "Read more about [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizers](https://pytorch.org/docs/stable/optim.html) supported by PyTorch.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8BgdSHzyl1cM"
   },
   "source": [
    "StopWatch.start('define-loss')\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "StopWatch.stop('define-loss')\n",
    "StopWatch.progress(10, filename=filename)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cloudmesh status=running progress=5 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=5 pid=2156'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BjYhjdFn9uG"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PgZDncI-mEoM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3205000a-7dd0-474c-bfea-6685b1b33859"
   },
   "source": [
    "StopWatch.start('train')\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_per_epoch = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Gradients cleared per batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass input to the model\n",
    "        output = model(images)\n",
    "        # Calculate loss after training compared to labels\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # backpropagation \n",
    "        loss.backward()\n",
    "        \n",
    "        # optimizer step to update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_per_epoch += loss.item()\n",
    "    average_loss = loss_per_epoch / len(train_loader)\n",
    "    print(\"Epoch {} - Training loss: {}\".format(epoch, average_loss))\n",
    "\n",
    "StopWatch.stop('train')\n",
    "StopWatch.progress(95, filename=filename)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.8226527945359547\n",
      "Epoch 1 - Training loss: 0.22889503665367764\n",
      "Epoch 2 - Training loss: 0.15277579474672676\n",
      "Epoch 3 - Training loss: 0.12439302523223063\n",
      "Epoch 4 - Training loss: 0.10396520219407976\n",
      "# cloudmesh status=running progress=97 pid=2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# cloudmesh status=running progress=97 pid=2156'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn2Wh1AQoAgr"
   },
   "source": [
    "## Test\n",
    "\n",
    "Similar to training data loader, we use the validation loader to load batch by batch and run the feed-forward network to get the expected prediction and compared to the label associated with the data point. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdOIB_sQmX6J",
    "outputId": "2169078c-1f2f-4cf4-d165-4f640d991702"
   },
   "source": [
    "StopWatch.start('test')\n",
    "\n",
    "correct_predictions, all_count = 0, 0\n",
    "# enumerate data from the data validation loader (loads a batch at a time)\n",
    "for batch_id, (images,labels) in enumerate(validation_loader):\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    # at prediction stage, only feed-forward calculation is required. \n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    # Output layer of the network uses a LogSoftMax layer\n",
    "    # Hence the probability must be calculated with the exponential values. \n",
    "    # The final layer returns an array of probabilities for each label\n",
    "    # Pick the maximum probability and the corresponding index\n",
    "    # The corresponding index is the predicted label \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_predictions += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(f\"Model Accuracy {(correct_predictions/all_count) * 100} %\")\n",
    "\n",
    "StopWatch.stop('test')\n",
    "StopWatch.stop('total')\n",
    "StopWatch.progress(100, filename=filename)\n",
    "\n",
    "if os_is_windows():\n",
    "    user = os.environ[\"USERNAME\"]\n",
    "else:\n",
    "    try:\n",
    "        user = os.environ['USER']\n",
    "    except:  # noqa: E722\n",
    "        user = os.system('basename $HOME')\n",
    "\n",
    "try:\n",
    "    gpuname = ''\n",
    "    for line in open('mlp_mnist.log', 'r'):\n",
    "        if 'GPU' in line and line[-2] == ')':\n",
    "            gpuname = gpuname + line[:line.find('(')] + '\\n'\n",
    "except:  # noqa: E722\n",
    "    gpuname = cpuinfo.get_cpu_info()['brand_raw']\n",
    "\n",
    "tag = 'mlp_mnist'\n",
    "\n",
    "StopWatch.benchmark(tag=tag, node=gpuname, user=user)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 95.93 %\n",
      "# cloudmesh status=running progress=100 pid=2156\n",
      "\n",
      "+------------------+----------------------------------------------------------------------------------+\n",
      "| Attribute        | Value                                                                            |\n",
      "|------------------+----------------------------------------------------------------------------------|\n",
      "| cpu              |                                                                                  |\n",
      "| cpu_cores        | 4                                                                                |\n",
      "| cpu_count        | 8                                                                                |\n",
      "| cpu_threads      | 8                                                                                |\n",
      "| date             | 2022-07-25 13:47:20.742343                                                       |\n",
      "| frequency        | scpufreq(current=2803.0, min=0.0, max=2803.0)                                    |\n",
      "| mem.available    | 6.8 GiB                                                                          |\n",
      "| mem.free         | 6.8 GiB                                                                          |\n",
      "| mem.percent      | 56.8 %                                                                           |\n",
      "| mem.total        | 15.8 GiB                                                                         |\n",
      "| mem.used         | 9.0 GiB                                                                          |\n",
      "| platform.version | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free')                               |\n",
      "| python           | 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)] |\n",
      "| python.pip       | 22.1.2                                                                           |\n",
      "| python.version   | 3.10.5                                                                           |\n",
      "| sys.platform     | win32                                                                            |\n",
      "| uname.machine    | AMD64                                                                            |\n",
      "| uname.node       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz                                   |\n",
      "| uname.processor  | Intel64 Family 6 Model 140 Stepping 1, GenuineIntel                              |\n",
      "| uname.release    | 10                                                                               |\n",
      "| uname.system     | Windows                                                                          |\n",
      "| uname.version    | 10.0.22000                                                                       |\n",
      "| user             | abeck                                                                            |\n",
      "+------------------+----------------------------------------------------------------------------------+\n",
      "\n",
      "+------------------+----------+--------+--------+---------------------+-----------+-------+------------------------------------------------+--------+---------+----------------------------------------------------+\n",
      "| Name             | Status   |   Time |    Sum | Start               | tag       | msg   | Node                                           | User   | OS      | Version                                            |\n",
      "|------------------+----------+--------+--------+---------------------+-----------+-------+------------------------------------------------+--------+---------+----------------------------------------------------|\n",
      "| total            | ok       | 51.379 | 51.379 | 2022-07-25 13:46:27 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| import           | ok       |  3.134 |  3.134 | 2022-07-25 13:46:27 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| data-load        | ok       |  0.174 |  0.174 | 2022-07-25 13:46:30 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| data-pre-process | ok       |  0.037 |  0.037 | 2022-07-25 13:46:31 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| define-model     | ok       |  0.008 |  0.008 | 2022-07-25 13:46:31 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| define-loss      | ok       |  0     |  0     | 2022-07-25 13:46:31 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| train            | ok       | 45.544 | 45.544 | 2022-07-25 13:46:31 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "| test             | ok       |  2.387 |  2.387 | 2022-07-25 13:47:16 | mlp_mnist |       | 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz | abeck  | Windows | ('10', '10.0.22000', 'SP0', 'Multiprocessor Free') |\n",
      "+------------------+----------+--------+--------+---------------------+-----------+-------+------------------------------------------------+--------+---------+----------------------------------------------------+\n",
      "# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version\n",
      "# csv,total,ok,51.379,51.379,2022-07-25 13:46:27,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,import,ok,3.134,3.134,2022-07-25 13:46:27,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,data-load,ok,0.174,0.174,2022-07-25 13:46:30,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,data-pre-process,ok,0.037,0.037,2022-07-25 13:46:31,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,define-model,ok,0.008,0.008,2022-07-25 13:46:31,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,define-loss,ok,0.0,0.0,2022-07-25 13:46:31,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,train,ok,45.544,45.544,2022-07-25 13:46:31,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "# csv,test,ok,2.387,2.387,2022-07-25 13:47:16,mlp_mnist,None,11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz,abeck,Windows,('10', '10.0.22000', 'SP0', 'Multiprocessor Free')\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT0COkaGPlLO"
   },
   "source": [
    "### Reference: \n",
    "\n",
    "1. [Torch NN Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
    "2. [Handwritten Digit Recognition Using PyTorch — Intro To Neural Networks](https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627)\n",
    "3. [MNIST Handwritten Digit Recognition in PyTorch](https://nextjournal.com/gkoehler/pytorch-mnist)\n"
   ]
  }
 ]
}
